services:
  postgres:
    image: pgvector/pgvector:pg16
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT}:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./infra/db/init.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 3s
      retries: 20

  ollama:
    image: ollama/ollama:latest
    environment:
      OLLAMA_MODEL: ${OLLAMA_MODEL:-nomic-embed-text}
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
    entrypoint:
      - sh
      - -lc
      - |
        set -e
        MODEL="${OLLAMA_MODEL:-nomic-embed-text}"
        ollama serve &
        pid=$$!
        i=0
        until curl -sf http://127.0.0.1:11434/api/tags >/dev/null 2>&1; do
          i=$$((i + 1))
          if [ "$$i" -ge 60 ]; then
            echo "Ollama server did not become ready" >&2
            kill "$$pid" || true
            exit 1
          fi
          sleep 1
        done
        ollama pull "$$MODEL"
        wait "$$pid"

  api:
    build:
      context: ./apps/api
    environment:
      DATABASE_URL: postgresql+psycopg://app:app@postgres:5432/tmdb
      EMBEDDINGS_PROVIDER: ${EMBEDDINGS_PROVIDER}
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL}
      OLLAMA_MODEL: ${OLLAMA_MODEL}
      AWS_REGION: ${AWS_REGION}
      BEDROCK_EMBED_MODEL_ID: ${BEDROCK_EMBED_MODEL_ID}
      EMBEDDING_DIM: ${EMBEDDING_DIM}
    ports:
      - "${API_PORT}:8000"
    depends_on:
      postgres:
        condition: service_healthy

  web:
    build:
      context: ./apps/web
      args:
        VITE_API_URL: ${VITE_API_URL:-http://localhost:8000}
    ports:
      - "5173:80"
    depends_on:
      - api

volumes:
  pgdata:
  ollama:
